{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0988bf9",
        "outputId": "9f3aab2a-52be-4fdd-dad5-eab9456d16ec"
      },
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install pyaudio\n",
        "!pip install pipwin\n",
        "!pipwin install pyaudio\n",
        "!pip install pocketsphinx\n",
        "!pip install pydub\n",
        "!pip install librosa\n",
        "!pip install soundfile\n",
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install sklearn\n",
        "!pip install tensorflow-lite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.14.1)\n",
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pyaudio)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pipwin in /usr/local/lib/python3.11/dist-packages (0.5.2)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from pipwin) (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pipwin) (2.32.3)\n",
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.11/dist-packages (from pipwin) (2.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from pipwin) (1.17.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from pipwin) (4.13.4)\n",
            "Requirement already satisfied: js2py in /usr/local/lib/python3.11/dist-packages (from pipwin) (0.74)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pipwin) (25.0)\n",
            "Requirement already satisfied: pySmartDL>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pipwin) (1.3.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9.0->pipwin) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9.0->pipwin) (4.14.1)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.11/dist-packages (from js2py->pipwin) (5.3.1)\n",
            "Requirement already satisfied: pyjsparser>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from js2py->pipwin) (2.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pipwin) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pipwin) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pipwin) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pipwin) (2025.7.14)\n",
            "/usr/local/lib/python3.11/dist-packages/pipwin/command.py:66: UserWarning: Found a non Windows system. Package installation might not work.\n",
            "  warn(\"Found a non Windows system. Package installation might not work.\")\n",
            "Building cache. Hang on . . .\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pipwin\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pipwin/command.py\", line 84, in main\n",
            "    cache = pipwin.PipwinCache()\n",
            "            ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pipwin/pipwin.py\", line 210, in __init__\n",
            "    self.data = build_cache()\n",
            "                ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pipwin/pipwin.py\", line 103, in build_cache\n",
            "    dl_function = re.search(r\"function dl.*\\}\", soup.find(\"script\").string).group(0)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'group'\n",
            "Requirement already satisfied: pocketsphinx in /usr/local/lib/python3.11/dist-packages (5.0.4)\n",
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.11/dist-packages (from pocketsphinx) (0.5.2)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice->pocketsphinx) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice->pocketsphinx) (2.22)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.7.14)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-lite (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-lite\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip archive.zip\n",
        "!unzip RakshaKavach_Dataset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv6nXhXtTrb6",
        "outputId": "8e8bf85e-220e-4a0e-b4b2-841da511351a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open archive.zip, archive.zip.zip or archive.zip.ZIP.\n",
            "Archive:  RakshaKavach_Dataset.zip\n",
            "   creating: RakshaKavach_Dataset/\n",
            "   creating: RakshaKavach_Dataset/normal_sounds/\n",
            "   creating: RakshaKavach_Dataset/threat_sounds/\n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-01-01-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-01-01-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-01-01-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-01-01-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-01-01-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-01-01-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-01-01-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-01-01-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-01-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-01-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-01-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-01-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-01-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-01-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-01-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-01-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-02-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-02-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-02-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-02-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-02-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-02-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-02-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-02-02-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-01-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-01-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-01-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-01-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-01-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-01-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-01-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-01-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-02-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-02-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-02-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-02-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-02-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-02-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-02-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-03-02-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-01-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-01-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-01-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-01-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-01-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-01-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-01-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-01-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-02-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-02-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-02-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-02-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-02-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-02-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-02-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-04-02-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-01-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-01-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-01-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-01-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-01-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-01-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-01-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-01-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-02-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-02-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-02-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-02-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-02-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-02-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-02-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-05-02-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-01-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-01-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-01-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-01-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-01-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-01-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-01-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-01-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-02-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-02-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-02-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-02-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-02-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-02-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-02-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-06-02-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-01-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-01-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-01-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-01-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-01-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-01-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-01-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-01-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-02-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-02-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-02-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-02-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-02-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-02-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-02-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-07-02-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-01-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-01-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-01-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-01-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-01-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-01-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-01-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-01-02-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-02-01-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-02-01-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-02-01-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-02-01-02-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-02-02-01-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-02-02-01-24.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-02-02-02-10.wav  \n",
            "  inflating: RakshaKavach_Dataset/threat_sounds/03-01-08-02-02-02-24.wav  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Raksha Kavach: Voice Analysis Prototype (Updated & Corrected)\n",
        "# This script analyzes a given audio file for signs of distress using a multi-layered AI approach.\n",
        "# It is designed as a proof-of-concept and should not be used as a real-world safety device without extensive validation.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import csv\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "# Paths to the pre-trained models and their label maps.\n",
        "# Ensure you have downloaded these and placed them in the correct location.\n",
        "YAMNET_MODEL_PATH = \"/content/1.tflite\"\n",
        "YAMNET_CLASSES_PATH = \"/content/yamnet_class_map.csv\"\n",
        "\n",
        "# For SER, a pre-trained TFLite model is assumed.\n",
        "SER_MODEL_PATH = \"/content/SER_quant.tflite\"\n",
        "SER_CLASSES_PATH = \"models/ser_labels.txt\" # e.g., a text file with \"anger\", \"fear\", \"happy\", \"neutral\" on separate lines.\n",
        "\n",
        "# --- LAYER 1: SOUND EVENT DETECTION (YAMNet) ---\n",
        "\n",
        "class SoundEventDetector:\n",
        "    \"\"\"\n",
        "    Analyzes audio for general sound events using the YAMNet model.\n",
        "    Focuses on detecting universal sounds of distress like screams or shouts.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_path, classes_path):\n",
        "        if not os.path.exists(model_path) or not os.path.exists(classes_path):\n",
        "            raise FileNotFoundError(\"YAMNet model or class map not found. Please download them.\")\n",
        "\n",
        "        self.interpreter = tf.lite.Interpreter(model_path)\n",
        "        self.interpreter.allocate_tensors()\n",
        "        self.input_details = self.interpreter.get_input_details()\n",
        "        self.output_details = self.interpreter.get_output_details()\n",
        "\n",
        "        self.class_names = []\n",
        "        with open(classes_path, 'r') as f:\n",
        "            reader = csv.reader(f)\n",
        "            next(reader) # Skip header\n",
        "            for row in reader:\n",
        "                self.class_names.append(row[2])\n",
        "\n",
        "        # Threat sounds are now keywords to search for within the detected labels.\n",
        "        self.threat_sounds = {\n",
        "            \"scream\": 8, \"shout\": 7, \"yell\": 7, \"crying\": 5, \"sobbing\": 5,\n",
        "            \"glass\": 6, \"gunshot\": 10\n",
        "        }\n",
        "\n",
        "    def analyze(self, audio_data, sample_rate):\n",
        "        \"\"\"\n",
        "        Analyzes the audio data and returns detected threat sounds.\n",
        "        \"\"\"\n",
        "        if sample_rate != 16000:\n",
        "            audio_data = librosa.resample(audio_data, orig_sr=sample_rate, target_sr=16000)\n",
        "\n",
        "        input_len = self.input_details[0]['shape'][-1]\n",
        "\n",
        "        if audio_data.shape[0] < input_len:\n",
        "            audio_data = np.pad(audio_data, (0, input_len - audio_data.shape[0]))\n",
        "        else:\n",
        "            audio_data = audio_data[:input_len]\n",
        "\n",
        "        input_tensor = np.array(audio_data, dtype=np.float32)\n",
        "\n",
        "        self.interpreter.set_tensor(self.input_details[0]['index'], input_tensor)\n",
        "        self.interpreter.invoke()\n",
        "        scores = self.interpreter.get_tensor(self.output_details[0]['index'])[0]\n",
        "\n",
        "        print(\"\\n[Sound Event Detector Top 5 Detections]\")\n",
        "        top_5_indices = np.argsort(scores)[-5:][::-1]\n",
        "        for i in top_5_indices:\n",
        "            print(f\"- {self.class_names[i]}: {scores[i]:.4f}\")\n",
        "\n",
        "        detected_threats = []\n",
        "        high_confidence_indices = np.where(scores > 0.1)[0]\n",
        "\n",
        "        for index in high_confidence_indices:\n",
        "            detected_sound_label = self.class_names[index].lower()\n",
        "            confidence = scores[index]\n",
        "\n",
        "            for threat_keyword, score_weight in self.threat_sounds.items():\n",
        "                if threat_keyword in detected_sound_label:\n",
        "                    detected_threats.append({\n",
        "                        \"type\": \"Sound Event\",\n",
        "                        \"detail\": self.class_names[index],\n",
        "                        \"confidence\": float(confidence),\n",
        "                        \"score_impact\": int(score_weight * confidence)\n",
        "                    })\n",
        "                    break\n",
        "\n",
        "        return detected_threats\n",
        "\n",
        "# --- LAYER 2: SPEECH EMOTION RECOGNITION (Placeholder) ---\n",
        "\n",
        "class EmotionDetector:\n",
        "    \"\"\"\n",
        "    Analyzes detected speech for emotional content.\n",
        "    NOTE: This is a placeholder. Real implementation requires a specific SER model.\n",
        "    \"\"\"\n",
        "    def __init__(self, model_path, classes_path):\n",
        "        self.model_available = os.path.exists(model_path)\n",
        "        if not self.model_available:\n",
        "            print(\"\\n[INFO] Speech Emotion Recognition model not found. This analysis layer will be skipped.\")\n",
        "        self.threat_emotions = {\"fear\": 7, \"angry\": 5}\n",
        "\n",
        "    def analyze(self, audio_data, sample_rate):\n",
        "        if not self.model_available:\n",
        "            return []\n",
        "        return []\n",
        "\n",
        "# --- LAYER 3: KEYWORD SPOTTING (Online + Offline Support) ---\n",
        "\n",
        "class KeywordSpotter:\n",
        "    \"\"\"\n",
        "    Transcribes audio to text and searches for specific distress keywords.\n",
        "    NOTE: For offline mode, you must install PocketSphinx: pip install pocketsphinx\n",
        "    \"\"\"\n",
        "    def __init__(self, use_offline=False):\n",
        "        self.recognizer = sr.Recognizer()\n",
        "        self.use_offline = use_offline\n",
        "        self.distress_keywords = {\n",
        "            \"help\": 8, \"stop\": 7, \"police\": 8, \"save\": 8,\n",
        "            \"kaapaadandi\": 9, \"aapu\": 7, \"bachao\": 8\n",
        "        }\n",
        "\n",
        "    def analyze(self, audio_file_path):\n",
        "        detected_threats = []\n",
        "        try:\n",
        "            with sr.AudioFile(audio_file_path) as source:\n",
        "                audio_data = self.recognizer.record(source)\n",
        "                text = \"\"\n",
        "                try:\n",
        "                    if self.use_offline:\n",
        "                        print(\"\\n[Transcription Mode: Offline - PocketSphinx]\")\n",
        "                        text = self.recognizer.recognize_sphinx(audio_data).lower()\n",
        "                    else:\n",
        "                        print(\"\\n[Transcription Mode: Online - Google API]\")\n",
        "                        text = self.recognizer.recognize_google(audio_data).lower()\n",
        "                except sr.RequestError:\n",
        "                    print(\"\\n[API Fallback]: Online API failed, trying offline engine...\")\n",
        "                    try:\n",
        "                        text = self.recognizer.recognize_sphinx(audio_data).lower()\n",
        "                    except sr.UnknownValueError:\n",
        "                         print(\"\\n[Transcription Error]: Offline engine could not understand audio.\")\n",
        "                         return []\n",
        "                except sr.UnknownValueError:\n",
        "                    print(\"\\n[Transcription Error]: Could not understand audio.\")\n",
        "                    return []\n",
        "\n",
        "                print(f\"[Transcription Result]: \\\"{text}\\\"\")\n",
        "\n",
        "                for keyword, score_weight in self.distress_keywords.items():\n",
        "                    if keyword in text:\n",
        "                        detected_threats.append({\n",
        "                            \"type\": \"Keyword\",\n",
        "                            \"detail\": f\"'{keyword}' detected\",\n",
        "                            \"confidence\": 1.0,\n",
        "                            \"score_impact\": score_weight\n",
        "                        })\n",
        "        except Exception as e:\n",
        "            print(f\"[Keyword Spotter Error]: An unexpected error occurred: {e}\")\n",
        "\n",
        "        return detected_threats\n",
        "\n",
        "# --- MAIN FUSION ENGINE ---\n",
        "\n",
        "def run_voice_analysis(audio_file_path, use_offline_transcription=False):\n",
        "    \"\"\"\n",
        "    Main function to run the entire analysis pipeline on a given audio file.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(audio_file_path):\n",
        "        print(f\"Error: Audio file not found at '{audio_file_path}'\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n--- Raksha Kavach: Voice Analysis Report ---\")\n",
        "    print(f\"File: {audio_file_path}\")\n",
        "    print(\"Initializing analysis engines...\")\n",
        "\n",
        "    temp_wav_path = \"/content/temp_analysis_audio.wav\"\n",
        "    try:\n",
        "        audio = AudioSegment.from_file(audio_file_path)\n",
        "        audio.set_channels(1).export(temp_wav_path, format=\"wav\")\n",
        "        waveform, sample_rate = sf.read(temp_wav_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading or converting audio file: {e}\")\n",
        "        if os.path.exists(temp_wav_path):\n",
        "            os.remove(temp_wav_path)\n",
        "        return\n",
        "\n",
        "    sound_detector = SoundEventDetector(YAMNET_MODEL_PATH, YAMNET_CLASSES_PATH)\n",
        "    emotion_detector = EmotionDetector(SER_MODEL_PATH, SER_CLASSES_PATH)\n",
        "    keyword_spotter = KeywordSpotter(use_offline=use_offline_transcription)\n",
        "\n",
        "    print(\"\\n[ANALYSIS STARTED]\")\n",
        "    all_evidence = []\n",
        "    all_evidence.extend(sound_detector.analyze(waveform, sample_rate))\n",
        "    all_evidence.extend(emotion_detector.analyze(waveform, sample_rate))\n",
        "    all_evidence.extend(keyword_spotter.analyze(temp_wav_path))\n",
        "\n",
        "    print(\"\\n[ANALYSIS COMPLETE]\")\n",
        "    total_threat_score = 0\n",
        "\n",
        "    if not all_evidence:\n",
        "        print(\"\\nNo specific threats detected.\")\n",
        "    else:\n",
        "        print(\"\\nEVIDENCE DETECTED:\")\n",
        "        unique_evidence = [dict(t) for t in {tuple(d.items()) for d in all_evidence}]\n",
        "        for evidence in unique_evidence:\n",
        "            print(f\"- [{evidence['type']:<12}]: {evidence['detail']} (Impact: +{evidence['score_impact']})\")\n",
        "            total_threat_score += evidence['score_impact']\n",
        "\n",
        "    # --- IMPROVEMENT: Three-tiered assessment logic ---\n",
        "    sos_threshold = 9\n",
        "    pre_alert_threshold = 5\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"FINAL THREAT SCORE: {total_threat_score}\")\n",
        "    print(f\"(Pre-Alert Threshold: {pre_alert_threshold}, SOS Threshold: {sos_threshold})\")\n",
        "\n",
        "    if total_threat_score >= sos_threshold:\n",
        "        print(\"ASSESSMENT: HIGH CONFIDENCE THREAT DETECTED.\")\n",
        "        print(\"ACTION:     Initiating IMMEDIATE SOS Protocol.\")\n",
        "    elif total_threat_score >= pre_alert_threshold:\n",
        "        print(\"ASSESSMENT: POTENTIAL THREAT DETECTED.\")\n",
        "        print(\"ACTION:     Entering PRE-ALERT mode. Awaiting user confirmation or timeout.\")\n",
        "    else:\n",
        "        print(\"ASSESSMENT: No immediate voice threats identified.\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    if os.path.exists(temp_wav_path):\n",
        "        os.remove(temp_wav_path)\n",
        "\n",
        "# --- SCRIPT ENTRY POINT ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"DISCLAIMER: This is a prototype for demonstration purposes.\")\n",
        "    print(\"It is NOT a life-saving device. Accuracy depends heavily on audio quality and model performance.\\n\")\n",
        "\n",
        "    sample_audio = \"/content/woman-screaming-sfx-screaming-sound-effect-320169.mp3\"\n",
        "\n",
        "    run_voice_analysis(sample_audio, use_offline_transcription=False)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DISCLAIMER: This is a prototype for demonstration purposes.\n",
            "It is NOT a life-saving device. Accuracy depends heavily on audio quality and model performance.\n",
            "\n",
            "\n",
            "--- Raksha Kavach: Voice Analysis Report ---\n",
            "File: /content/woman-screaming-sfx-screaming-sound-effect-320169.mp3\n",
            "Initializing analysis engines...\n",
            "\n",
            "[ANALYSIS STARTED]\n",
            "\n",
            "[Sound Event Detector Top 5 Detections]\n",
            "- Screaming: 0.8516\n",
            "- Speech: 0.0430\n",
            "- Inside, small room: 0.0430\n",
            "- Shout: 0.0195\n",
            "- Yell: 0.0156\n",
            "\n",
            "[Transcription Mode: Online - Google API]\n",
            "\n",
            "[Transcription Error]: Could not understand audio.\n",
            "\n",
            "[ANALYSIS COMPLETE]\n",
            "\n",
            "EVIDENCE DETECTED:\n",
            "- [Sound Event ]: Screaming (Impact: +6)\n",
            "\n",
            "========================================\n",
            "FINAL THREAT SCORE: 6\n",
            "(Pre-Alert Threshold: 5, SOS Threshold: 9)\n",
            "ASSESSMENT: POTENTIAL THREAT DETECTED.\n",
            "ACTION:     Entering PRE-ALERT mode. Awaiting user confirmation or timeout.\n",
            "========================================\n"
          ]
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3YKeDL5_7ce",
        "outputId": "f2ca9086-2ff6-44b9-9b84-c5aa3fcf3597"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Raksha Kavach: Custom AI Model Training Script\n",
        "# This script trains a custom audio classification model to distinguish between\n",
        "# \"threat\" and \"normal\" sounds, and exports it as a .tflite file.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import librosa\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import shutil\n",
        "\n",
        "# --- 1. CONFIGURATION & SETUP ---\n",
        "\n",
        "# Define paths. You will need to create these folders and place your audio files inside.\n",
        "DATASET_PATH = \"/content/RakshaKavach_Dataset\"\n",
        "THREAT_SOUNDS_PATH = os.path.join(DATASET_PATH, \"threat_sounds\")\n",
        "NORMAL_SOUNDS_PATH = os.path.join(DATASET_PATH, \"normal_sounds\")\n",
        "MODEL_SAVE_PATH = \"/content/raksha_kavach_model.h5\"\n",
        "TFLITE_MODEL_SAVE_PATH = \"/content/raksha_kavach_model.tflite\"\n",
        "\n",
        "# Audio processing parameters\n",
        "SAMPLE_RATE = 22050\n",
        "DURATION = 3  # seconds\n",
        "N_MELS = 128  # Number of Mel bands\n",
        "N_FFT = 2048\n",
        "HOP_LENGTH = 512\n",
        "\n",
        "def setup_directory_structure():\n",
        "    \"\"\"Creates the necessary folders for the training data.\"\"\"\n",
        "    print(\"Setting up directory structure...\")\n",
        "    if os.path.exists(DATASET_PATH):\n",
        "        shutil.rmtree(DATASET_PATH) # Clean up previous runs\n",
        "    os.makedirs(THREAT_SOUNDS_PATH)\n",
        "    os.makedirs(NORMAL_SOUNDS_PATH)\n",
        "    print(f\"Please upload your 'threat' audio files to: {THREAT_SOUNDS_PATH}\")\n",
        "    print(f\"Please upload your 'normal' audio files to: {NORMAL_SOUNDS_PATH}\")\n",
        "    print(\"Once uploaded, run the rest of the cells.\")\n",
        "\n",
        "# --- 2. FEATURE EXTRACTION (Audio to Image) ---\n",
        "\n",
        "def audio_to_mel_spectrogram(file_path):\n",
        "    \"\"\"\n",
        "    Loads an audio file and converts it into a Mel Spectrogram.\n",
        "    A spectrogram is a visual representation of sound, which a CNN can analyze like an image.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path, sr=SAMPLE_RATE, duration=DURATION)\n",
        "\n",
        "        # Pad or truncate to a fixed length\n",
        "        target_length = DURATION * sr\n",
        "        if len(y) < target_length:\n",
        "            y = np.pad(y, (0, target_length - len(y)))\n",
        "        else:\n",
        "            y = y[:target_length]\n",
        "\n",
        "        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=N_MELS)\n",
        "        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "        return log_mel_spectrogram\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- 3. DATA LOADING & PREPARATION ---\n",
        "\n",
        "def load_data(data_path):\n",
        "    \"\"\"\n",
        "    Loads all audio files from the subdirectories, extracts features, and assigns labels.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    labels_map = {\"normal_sounds\": 0, \"threat_sounds\": 1}\n",
        "\n",
        "    for label, folder_name in enumerate(labels_map):\n",
        "        folder_path = os.path.join(data_path, folder_name)\n",
        "        print(f\"\\nLoading files from: {folder_path}\")\n",
        "\n",
        "        file_count = 0\n",
        "        for filename in os.listdir(folder_path):\n",
        "            if filename.endswith(('.wav', '.mp3', '.ogg')):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                spectrogram = audio_to_mel_spectrogram(file_path)\n",
        "\n",
        "                if spectrogram is not None:\n",
        "                    X.append(spectrogram)\n",
        "                    y.append(labels_map[folder_name])\n",
        "                    file_count += 1\n",
        "        print(f\"Loaded {file_count} files.\")\n",
        "\n",
        "    if not X:\n",
        "        print(\"\\nERROR: No audio files were loaded. Please check your dataset paths and file formats.\")\n",
        "        return None, None\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# --- 4. MODEL ARCHITECTURE (The AI Brain) ---\n",
        "\n",
        "def build_model(input_shape):\n",
        "    \"\"\"\n",
        "    Builds a Convolutional Neural Network (CNN) designed for classifying spectrograms.\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        Input(shape=input_shape),\n",
        "\n",
        "        Conv2D(32, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        Dense(2, activation='softmax') # 2 outputs: normal (0) and threat (1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# --- 5. THE COMPLETE TRAINING PIPELINE ---\n",
        "\n",
        "def train_model():\n",
        "    \"\"\"\n",
        "    Runs the entire training process from data loading to model saving.\n",
        "    \"\"\"\n",
        "    # Load and preprocess the data\n",
        "    X, y = load_data(DATASET_PATH)\n",
        "    if X is None:\n",
        "        return\n",
        "\n",
        "    # Add a channel dimension for the CNN (like a grayscale image)\n",
        "    X = X[..., np.newaxis]\n",
        "    y = to_categorical(y, num_classes=2)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    print(f\"\\nTraining data shape: {X_train.shape}\")\n",
        "    print(f\"Test data shape: {X_test.shape}\")\n",
        "\n",
        "    # Build the model\n",
        "    model = build_model(X_train.shape[1:])\n",
        "    model.summary()\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\n--- Starting Model Training ---\")\n",
        "    history = model.fit(X_train, y_train,\n",
        "                        epochs=50,\n",
        "                        batch_size=32,\n",
        "                        validation_data=(X_test, y_test),\n",
        "                        callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "    print(\"\\n--- Training Complete ---\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss, accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"\\nFinal Test Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "    # Save the trained Keras model\n",
        "    model.save(MODEL_SAVE_PATH)\n",
        "    print(f\"\\nKeras model saved to: {MODEL_SAVE_PATH}\")\n",
        "\n",
        "    # Convert and save the TensorFlow Lite model\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    with open(TFLITE_MODEL_SAVE_PATH, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"TFLite model saved to: {TFLITE_MODEL_SAVE_PATH}\")\n",
        "    print(\"\\nThis .tflite file is the 'engine' you can now use in your analysis application.\")\n",
        "\n",
        "# --- SCRIPT EXECUTION ---\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    setup_directory_structure()\n",
        "    # train_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1Vk3D5RV-Dn",
        "outputId": "68714e68-6257-4dd7-8362-4252a4fa680b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up directory structure...\n",
            "Please upload your 'threat' audio files to: /content/RakshaKavach_Dataset/threat_sounds\n",
            "Please upload your 'normal' audio files to: /content/RakshaKavach_Dataset/normal_sounds\n",
            "Once uploaded, run the rest of the cells.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}